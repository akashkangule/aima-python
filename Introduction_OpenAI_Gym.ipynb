{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UImTzmGTIeX9"
      },
      "source": [
        "# Part 1: Introduction to the OpenAI Gym\n",
        "\n",
        "[OpenAI Gym](https://gym.openai.com/) aims to provide an easy-to-setup general-intelligence benchmark with a wide variety of different environments. The goal is to standardize how environments are defined in AI research publications so that published research becomes more easily reproducible. The project claims to provide the user with a simple interface. As of June 2017, developers can only use Gym with Python. \n",
        "\n",
        "OpenAI gym is pip-installed onto your local machine.  There are a few significant limitations to be aware of:\n",
        "\n",
        "* OpenAI Gym Atari only **directly** supports Linux and Macintosh\n",
        "* OpenAI Gym Atari can be used with Windows; however, it requires a particular [installation procedure](https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30)\n",
        "* OpenAI Gym can not directly render animated games in Google CoLab.\n",
        "\n",
        "Because OpenAI Gym requires a graphics display, the only way to display Gym in Google CoLab is an embedded video.  The presentation of OpenAI Gym game animations in Google CoLab is discussed later in this module.\n",
        "\n",
        "### OpenAI Gym Leaderboard\n",
        "\n",
        "The OpenAI Gym does have a leaderboard, similar to Kaggle; however, the OpenAI Gym's leaderboard is much more informal compared to Kaggle.  The user's local machine performs all scoring.  As a result, the OpenAI gym's leaderboard is strictly an \"honor's system.\"  The leaderboard is maintained the following GitHub repository:\n",
        "\n",
        "* [OpenAI Gym Leaderboard](https://github.com/openai/gym/wiki/Leaderboard)\n",
        "\n",
        "If you submit a score, you are required to provide a writeup with sufficient instructions to reproduce your result. A video of your results is suggested, but not required.\n",
        "\n",
        "### Looking at Gym Environments\n",
        "\n",
        "The centerpiece of Gym is the environment, which defines the \"game\" in which your reinforcement algorithm will compete.  An environment does not need to be a game; however, it describes the following game-like features:\n",
        "* **action space**: What actions can we take on the environment, at each step/episode, to alter the environment.\n",
        "* **observation space**: What is the current state of the portion of the environment that we can observe. Usually, we can see the entire environment.\n",
        "\n",
        "Before we begin to look at Gym, it is essential to understand some of the terminology used by this library.\n",
        "\n",
        "* **Agent** - The machine learning program or model that controls the actions.\n",
        "Step - One round of issuing actions that affect the observation space.\n",
        "* **Episode** - A collection of steps that terminates when the agent fails to meet the environment's objective, or the episode reaches the maximum number of allowed steps.\n",
        "* **Render** - Gym can render one frame for display after each episode.\n",
        "* **Reward** - A positive reinforcement that can occur at the end of each episode, after the agent acts.\n",
        "* **Nondeterministic** - For some environments, randomness is a factor in deciding what effects actions have on reward and changes to the observation space.\n",
        "\n",
        "It is important to note that many of the gym environments specify that they are not nondeterministic even though they make use of random numbers to process actions. It is generally agreed upon (based on the gym GitHub issue tracker) that nondeterministic property means that a deterministic environment will still behave randomly even when given consistent seed value. The seed method of an environment can be used by the program to seed the random number generator for the environment.\n",
        "\n",
        "The Gym library allows us to query some of these attributes from environments.  I created the following function to query gym environments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cciTuR2MIeX-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import ale_py\n",
        "\n",
        "def query_environment(name):\n",
        "  env = gym.make(name)\n",
        "  spec = gym.spec(name)\n",
        "  print(f\"Action Space: {env.action_space}\")\n",
        "  print(f\"Observation Space: {env.observation_space}\")\n",
        "  print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n",
        "  print(f\"Nondeterministic: {spec.nondeterministic}\")\n",
        "  print(f\"Reward Range: {env.reward_range}\")\n",
        "  print(f\"Reward Threshold: {spec.reward_threshold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRXfAdwFDwUm"
      },
      "source": [
        "We will begin by looking at the MountainCar-v0 environment, which challenges an underpowered car to escape the valley between two mountains.  The following code describes the Mountian Car environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYwy9cjlJjEH",
        "outputId": "cf58d7e0-16b6-4138-9a72-6f9f80da560e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Discrete(3)\n",
            "Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
            "Max Episode Steps: 200\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: -110.0\n"
          ]
        }
      ],
      "source": [
        "#  nondeterministic property means that a deterministic environment will still behave randomly even when given consistent seed value\n",
        "query_environment(\"MountainCar-v0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TsQiaGJE3UA"
      },
      "source": [
        "There are three distinct actions that can be taken: accelrate forward, decelerate, or accelerate backwards.  The observation space contains two continuous (floating point) values, as evident by the box object. The observation space is simply the position and velocity of the car.  The car has 200 steps to escape for each epasode.  You would have to look at the code to know, but the mountian car recieves no incramental reward.  The only reward for the car is given when it escapes the valley.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF4n5cYEMyru",
        "outputId": "2d62baf8-b4d6-4842-d528-07179e062733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Discrete(2)\n",
            "Observation Space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "Max Episode Steps: 500\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: 475.0\n"
          ]
        }
      ],
      "source": [
        "query_environment(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwvVKrNebUHJ"
      },
      "source": [
        "The CartPole-v1 environment challenges the agent to move a cart while keeping a pole balanced. The environment has an observation space of 4 continuous numbers:\n",
        "\n",
        "* Cart Position\n",
        "* Cart Velocity\n",
        "* Pole Angle\n",
        "* Pole Velocity At Tip\n",
        "\n",
        "To achieve this goal, the agent can take the following actions:\n",
        "\n",
        "* Push cart to the left\n",
        "* Push cart to the right\n",
        "\n",
        "There is also a continuous variant of the mountain car.  This version does not simply have the motor on or off.  For the continuous car the action space is a single floating point number that specifies how much forward or backward force is being applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAlaMcJmNSY0",
        "outputId": "a90b14ca-6f44-4a20-a08d-a8256b0e4b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Box(-1.0, 1.0, (1,), float32)\n",
            "Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
            "Max Episode Steps: 999\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: 90.0\n"
          ]
        }
      ],
      "source": [
        "query_environment(\"MountainCarContinuous-v0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBrlG1t6ceIa"
      },
      "source": [
        "\n",
        "Atari games, like breakout can use an observation space that is either equal to the size of the Atari screen (210x160) or even use the RAM memory of the Atari (128 bytes) to determine the state of the game.  Yes thats bytes, not kilobytes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndTb-9pgJizW",
        "outputId": "a2ead347-33fc-4eb8-a281-f2cce606acc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Discrete(4)\n",
            "Observation Space: Box(0, 255, (210, 160, 3), uint8)\n",
            "Max Episode Steps: None\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: None\n"
          ]
        }
      ],
      "source": [
        "query_environment(\"ALE/Breakout-v5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni1rxzmLKAdH",
        "outputId": "f217c338-c8fb-459a-b8b4-d0282fd080ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Discrete(4)\n",
            "Observation Space: Box(0, 255, (128,), uint8)\n",
            "Max Episode Steps: None\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: None\n"
          ]
        }
      ],
      "source": [
        "query_environment(\"ALE/Breakout-ram-v5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E253PBGPRuw"
      },
      "source": [
        "### Render OpenAI Gym Environments from CoLab\n",
        "\n",
        "It is possible to visualize the game your agent is playing, even on CoLab.  This section provides information on how to generate a video in CoLab that shows you an episode of the game your agent is playing. This video process is based on suggestions found [here](https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t).\n",
        "\n",
        "Begin by installing **pyvirtualdisplay** and **python-opengl**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uF92FCzZMWPn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n",
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS7L8kFMLkjN"
      },
      "source": [
        "Next, we install needed requirements to display an Atari game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78BfQoQKOq7z",
        "outputId": "f175d6d5-195e-460f-c525-74c6819dea60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n",
            "The system cannot find the path specified.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: setuptools in c:\\users\\amkak\\appdata\\roaming\\python\\python38\\site-packages (65.5.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n",
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjTHm2SpLz10"
      },
      "source": [
        "Next we define functions used to show the video by adding it to the CoLab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T9RpF49oOsZj"
      },
      "outputs": [
        {
          "ename": "EasyProcessError",
          "evalue": "start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[WinError 2] The system cannot find the file specified return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\easyprocess\\__init__.py:176\u001b[0m, in \u001b[0;36mEasyProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopen \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(\n\u001b[0;32m    177\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcmd,\n\u001b[0;32m    178\u001b[0m         stdout\u001b[39m=\u001b[39;49mstdout,\n\u001b[0;32m    179\u001b[0m         stderr\u001b[39m=\u001b[39;49mstderr,\n\u001b[0;32m    180\u001b[0m         cwd\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcwd,\n\u001b[0;32m    181\u001b[0m         env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m oserror:\n",
            "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    856\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 858\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    859\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    860\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    861\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    862\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    863\u001b[0m                         errread, errwrite,\n\u001b[0;32m    864\u001b[0m                         restore_signals, start_new_session)\n\u001b[0;32m    865\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\subprocess.py:1311\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1311\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1312\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1313\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1314\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1315\u001b[0m                              creationflags,\n\u001b[0;32m   1316\u001b[0m                              env,\n\u001b[0;32m   1317\u001b[0m                              cwd,\n\u001b[0;32m   1318\u001b[0m                              startupinfo)\n\u001b[0;32m   1319\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1320\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mEasyProcessError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [13], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyvirtualdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Display\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m \u001b[39mimport\u001b[39;00m display \u001b[39mas\u001b[39;00m ipythondisplay\n\u001b[1;32m---> 10\u001b[0m display \u001b[39m=\u001b[39m Display(visible\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, size\u001b[39m=\u001b[39;49m(\u001b[39m1400\u001b[39;49m, \u001b[39m900\u001b[39;49m))\n\u001b[0;32m     11\u001b[0m display\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     13\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mUtility functions to enable video recording of gym environment \u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mand displaying it.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mTo enable video, just do \"env = wrap_env(env)\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyvirtualdisplay\\display.py:54\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[1;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m:\n\u001b[0;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munknown backend: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend)\n\u001b[1;32m---> 54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m     55\u001b[0m     size\u001b[39m=\u001b[39;49msize,\n\u001b[0;32m     56\u001b[0m     color_depth\u001b[39m=\u001b[39;49mcolor_depth,\n\u001b[0;32m     57\u001b[0m     bgcolor\u001b[39m=\u001b[39;49mbgcolor,\n\u001b[0;32m     58\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m     59\u001b[0m     use_xauth\u001b[39m=\u001b[39;49muse_xauth,\n\u001b[0;32m     60\u001b[0m     \u001b[39m# check_startup=check_startup,\u001b[39;49;00m\n\u001b[0;32m     61\u001b[0m     extra_args\u001b[39m=\u001b[39;49mextra_args,\n\u001b[0;32m     62\u001b[0m     manage_global_env\u001b[39m=\u001b[39;49mmanage_global_env,\n\u001b[0;32m     63\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m     64\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyvirtualdisplay\\xvfb.py:44\u001b[0m, in \u001b[0;36mXvfbDisplay.__init__\u001b[1;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fbdir \u001b[39m=\u001b[39m fbdir\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dpi \u001b[39m=\u001b[39m dpi\n\u001b[1;32m---> 44\u001b[0m AbstractDisplay\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m     46\u001b[0m     PROGRAM,\n\u001b[0;32m     47\u001b[0m     use_xauth\u001b[39m=\u001b[39;49muse_xauth,\n\u001b[0;32m     48\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m     49\u001b[0m     extra_args\u001b[39m=\u001b[39;49mextra_args,\n\u001b[0;32m     50\u001b[0m     manage_global_env\u001b[39m=\u001b[39;49mmanage_global_env,\n\u001b[0;32m     51\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyvirtualdisplay\\abstractdisplay.py:88\u001b[0m, in \u001b[0;36mAbstractDisplay.__init__\u001b[1;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_wfd \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries_current \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m helptext \u001b[39m=\u001b[39m get_helptext(program)\n\u001b[0;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_displayfd \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-displayfd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m helptext\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_displayfd:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyvirtualdisplay\\util.py:10\u001b[0m, in \u001b[0;36mget_helptext\u001b[1;34m(program)\u001b[0m\n\u001b[0;32m      8\u001b[0m p\u001b[39m.\u001b[39menable_stdout_log \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m p\u001b[39m.\u001b[39menable_stderr_log \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m p\u001b[39m.\u001b[39;49mcall()\n\u001b[0;32m     11\u001b[0m helptext \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mstderr\n\u001b[0;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m helptext\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\easyprocess\\__init__.py:147\u001b[0m, in \u001b[0;36mEasyProcess.call\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39m\"\"\"Run command with arguments. Wait for command to complete.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[39msame as:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart()\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    148\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_alive():\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\easyprocess\\__init__.py:186\u001b[0m, in \u001b[0;36mEasyProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mOSError exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, oserror)\n\u001b[0;32m    185\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moserror \u001b[39m=\u001b[39m oserror\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m EasyProcessError(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstart error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_started \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    188\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mprocess was started (pid=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid)\n",
            "\u001b[1;31mEasyProcessError\u001b[0m: start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[WinError 2] The system cannot find the file specified return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6NATj-kNADT"
      },
      "source": [
        "Now we are ready to play the game.  We use a simple random agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "XDKGJ9A3O8fT",
        "outputId": "66acbfe3-c530-4a53-e4f6-33c1bfe970be"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'wrap_env' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#env = wrap_env(gym.make(\"MountainCar-v0\"))\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m env \u001b[39m=\u001b[39m wrap_env(gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mAtlantis-v0\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m observation \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'wrap_env' is not defined"
          ]
        }
      ],
      "source": [
        "#env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
        "env = wrap_env(gym.make(\"Atlantis-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True:\n",
        "  \n",
        "    env.render()\n",
        "    \n",
        "    #your agent goes here\n",
        "    action = env.action_space.sample() \n",
        "         \n",
        "    observation, reward, done, info = env.step(action) \n",
        "   \n",
        "        \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "t81_558_class_12_01_ai_gym.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
